{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a10b418-ac80-4187-a54e-f74066bca77a",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f059c-90c6-4964-a63d-fd1476a01bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b806b0-e1e0-4573-b393-9468b1da5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc22b5-9751-4c97-881a-6fb4b94c8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run /content/drive/MyDrive/DentistDataAnalysis/Experiments/Mappings.ipynb\n",
    "# %run /content/drive/MyDrive/DentistDataAnalysis/Experiments/ModelsImplementation.ipynb\n",
    "\n",
    "%run Mappings.ipynb\n",
    "%run ModelsImplementation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafc249-ed54-400f-8596-509d384c8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/'\n",
    "# RESULTS_DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/results/'\n",
    "DIR = ''\n",
    "RESULTS_DIR = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f2463-6e92-4cbd-a1b8-98d592143445",
   "metadata": {},
   "source": [
    "### Functions for strategies and balance transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5c46f-f845-4a0b-af4c-429d84aeb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy_data(strategy=None):\n",
    "    X_train = None\n",
    "    y_train = None\n",
    "    if strategy=='strategy1':\n",
    "        X_train = data_dropped.drop(columns=['Que16']).to_numpy()\n",
    "        y_train = data_dropped['Que16'].to_numpy()\n",
    "    elif strategy=='strategy2':\n",
    "        X_train = data_median.drop(columns=['Que16']).to_numpy()\n",
    "        y_train = data_median['Que16'].to_numpy()\n",
    "    elif strategy=='strategy3':\n",
    "        X_train = data_mean.drop(columns=['Que16']).to_numpy()\n",
    "        y_train = data_mean['Que16'].to_numpy()\n",
    "    elif strategy=='strategy4':\n",
    "        X_train = data_most_frequent.drop(columns=['Que16']).to_numpy()\n",
    "        y_train = data_most_frequent['Que16'].to_numpy()\n",
    "    else:\n",
    "        X_train = None\n",
    "        y_train = None\n",
    "    return X_train, y_train\n",
    "\n",
    "def get_balanced_data(X_train, y_train, balance=None, X_val=None, y_val=None):\n",
    "    X_balanced = None\n",
    "    y_balanced = None\n",
    "    train_val_indices = None\n",
    "    if balance=='no_balance':\n",
    "        X_balanced = X_train\n",
    "        y_balanced = y_train\n",
    "    elif balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_balanced, y_balanced = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_balanced, y_balanced = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_balanced, y_balanced = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_balanced = None\n",
    "        y_balanced = None\n",
    "        \n",
    "    if X_val is not None and y_val is not None:\n",
    "        ind_train = [ind for ind in range(0, len(X_balanced))]\n",
    "        ind_val = [ind for ind in range(len(X_balanced), len(X_balanced)+len(X_val))]\n",
    "        X_balanced = np.append(X_balanced, X_val, axis=0)\n",
    "        y_balanced = np.append(y_balanced, y_val, axis=0)\n",
    "        train_val_indices = [[ind_train, ind_val]]\n",
    "        \n",
    "    return X_balanced, y_balanced, train_val_indices\n",
    "\n",
    "def get_data_frames(data_train):\n",
    "    #strategy 1\n",
    "    data_dropped = data_train.dropna().reset_index(drop=True)\n",
    "    data_dropped = perform_mapping(data_dropped, questions_map_EN)\n",
    "    #strategy 2\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    data_median = pd.DataFrame(imputer.fit_transform(data_train))\n",
    "    data_median.columns = data_train.columns\n",
    "    data_median.index = data_train.index\n",
    "    data_median = perform_mapping(data_median, questions_map_EN)\n",
    "    #strategy 3\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    data_mean = pd.DataFrame(imputer.fit_transform(data_train))\n",
    "    data_mean.columns = data_train.columns\n",
    "    data_mean.index = data_train.index\n",
    "    # mean values are not integer numbers so rounding to int was necessary\n",
    "    data_mean = data_mean.round()\n",
    "    data_mean = perform_mapping(data_mean, questions_map_EN)\n",
    "    #strategy 4\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    data_most_frequent = pd.DataFrame(imputer.fit_transform(data_train))\n",
    "    data_most_frequent.columns = data_train.columns\n",
    "    data_most_frequent.index = data_train.index\n",
    "    data_most_frequent = perform_mapping(data_most_frequent, questions_map_EN)\n",
    "    \n",
    "    return data_dropped, data_median, data_mean, data_most_frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc59606-9b76-4102-bf37-43146d56303b",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe6cfa-18d6-450a-83ab-8792e4a8ae97",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c55e76-b922-4d2d-89ee-7ee2f829bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(DIR+'dataset/train_test/train_data.csv')\n",
    "data_test = pd.read_csv(DIR+'dataset/train_test/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed30dd-55cb-4a2e-b332-ae75e5845d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['Que1', 'Que2', 'Que3', 'Que4', 'Que5', 'Que6', 'Que10_a', 'Que10_b', 'Que10_c', 'Que10_d', 'Que10_e', 'Que10_f', 'Que14', 'Que15', 'Que17', 'Que18_age', 'Que19', 'Que20', 'Que21', 'Que22', 'Que_smoking']\n",
    "y_col = ['Que16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129d04f-fc3f-4fe3-884f-178a73506dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_mapped = perform_mapping(data_test, questions_map_EN)\n",
    "X_test = data_test.drop(columns=['Que16']).to_numpy()\n",
    "y_test = data_test['Que16'].to_numpy()\n",
    "data_dropped, data_median, data_mean, data_most_frequent = get_data_frames(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49220402-bfc4-4c7c-84fd-5cfd5bab0982",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65fa0f-507d-4d6f-90a9-7fd1826ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = ['strategy', 'model', 'balance', 'val_score', 'recall', 'accuracy', 'precision', 'roc_auc', 'f1-score', 'conf matrix', 'time', 'params']\n",
    "key = 0\n",
    "dict_metric = {}\n",
    "strategies = ['strategy1', 'strategy2', 'strategy3', 'strategy4']\n",
    "models = ['log_reg', 'dec_tree', 'rand_for']\n",
    "balances = ['no_balance', 'under', 'over', 'smoteenn']\n",
    "for strategy in strategies:\n",
    "    for model in models:\n",
    "        for balance in balances:\n",
    "            title = strategy + ' ' + model + ' ' + balance\n",
    "            print(title)\n",
    "            dict_metric[key] = []\n",
    "            dict_metric[key].extend([strategy, model, balance])\n",
    "            X_train, y_train = get_strategy_data(strategy)\n",
    "            X_train, y_train, _ = get_balanced_data(X_train, y_train, balance)\n",
    "            \n",
    "            try:\n",
    "                if model=='log_reg':\n",
    "                    metrics = perform_logit(X_train, y_train, X_test, y_test, X_cols, y_col)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                elif model=='dec_tree':\n",
    "                    metrics = perform_decision_tree(X_train, y_train, X_test, y_test)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                elif model=='rand_for':\n",
    "                    metrics = perform_random_forest(X_train, y_train, X_test, y_test, title)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                else:\n",
    "                    print('Not existing model!')\n",
    "                key+=1\n",
    "            except:\n",
    "                dict_metric[key].extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "                key+=1\n",
    "                continue\n",
    "result_df = pd.DataFrame.from_dict(dict_metric, orient='index', columns=result_cols)\n",
    "result_df.to_csv(RESULTS_DIR+'results_cross_val_'+str(time.time())+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14723795-a3ac-41c9-ad84-19e60aed5fc0",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729ff48-7f3f-4be5-a5ce-dcf860da7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(DIR+'dataset/train_val_test/train_data.csv')\n",
    "data_val = pd.read_csv(DIR+'dataset/train_val_test/val_data.csv')\n",
    "data_test = pd.read_csv(DIR+'dataset/train_val_test/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564c302-efa8-49b0-a8e9-3f1adcfaef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['Que1', 'Que2', 'Que3', 'Que4', 'Que5', 'Que6', 'Que10_a', 'Que10_b', 'Que10_c', 'Que10_d', 'Que10_e', 'Que10_f', 'Que14', 'Que15', 'Que17', 'Que18_age', 'Que19', 'Que20', 'Que21', 'Que22', 'Que_smoking']\n",
    "y_col = ['Que16']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9a5dc-e9da-4006-9f26-69294445bd79",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e42582-d090-4c32-a404-b184c6c28773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_mapped = perform_mapping(data_test, questions_map_EN)\n",
    "X_test = data_test.drop(columns=['Que16']).to_numpy()\n",
    "y_test = data_test['Que16'].to_numpy()\n",
    "data_val_mapped = perform_mapping(data_val, questions_map_EN)\n",
    "X_val = data_val.drop(columns=['Que16']).to_numpy()\n",
    "y_val = data_val['Que16'].to_numpy()\n",
    "data_dropped, data_median, data_mean, data_most_frequent = get_data_frames(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d322f4-7ba0-4790-907b-e705e6998d2b",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ad5fb-0ffc-44d2-b12d-03f5b93c41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = ['strategy', 'model', 'balance', 'val_score', 'recall', 'accuracy', 'precision', 'roc_auc', 'f1-score', 'conf matrix', 'time', 'params']\n",
    "key = 0\n",
    "dict_metric = {}\n",
    "strategies = ['strategy1', 'strategy2', 'strategy3', 'strategy4']\n",
    "models = ['log_reg', 'dec_tree', 'rand_for']\n",
    "balances = ['no_balance', 'under', 'over', 'smoteenn']\n",
    "for strategy in strategies:\n",
    "    for model in models:\n",
    "        for balance in balances:\n",
    "            title = strategy + ' ' + model + ' ' + balance\n",
    "            print(title)\n",
    "            dict_metric[key] = []\n",
    "            dict_metric[key].extend([strategy, model, balance])\n",
    "            X_train, y_train = get_strategy_data(strategy)\n",
    "            X_train, y_train, train_val_indices = get_balanced_data(X_train, y_train, balance, X_val, y_val)\n",
    "            \n",
    "            try:\n",
    "                if model=='log_reg':\n",
    "                    metrics = perform_logit(X_train, y_train, X_test, y_test, X_cols, y_col, train_val_indices)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                elif model=='dec_tree':\n",
    "                    metrics = perform_decision_tree(X_train, y_train, X_test, y_test, train_val_indices)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                elif model=='rand_for':\n",
    "                    metrics = perform_random_forest(X_train, y_train, X_test, y_test, title, train_val_indices)\n",
    "                    dict_metric[key].extend([metrics[0], metrics[1][0], metrics[1][1], metrics[1][2], metrics[1][3], metrics[1][4], metrics[1][5], metrics[2], metrics[3]])\n",
    "                else:\n",
    "                    print('Not existing model!')\n",
    "                key+=1\n",
    "            except:\n",
    "                dict_metric[key].extend([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "                key+=1\n",
    "                continue\n",
    "result_df = pd.DataFrame.from_dict(dict_metric, orient='index', columns=result_cols)\n",
    "result_df.to_csv(RESULTS_DIR+'results_val_'+str(time.time())+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
