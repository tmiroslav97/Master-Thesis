{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba6abad-3042-4bec-80b1-2b5cd1fa39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd13d1a-c5a3-487f-8327-598b5bfdeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_counts(data_subset):\n",
    "    for idx, col in enumerate(data_subset.columns):\n",
    "        print(questions[col]['text'])\n",
    "        print('Count:' + '\\t' + 'Answer:')\n",
    "        val_cnts = data_subset[col].value_counts()\n",
    "        for pos, ind in enumerate(val_cnts.index):\n",
    "            count = val_cnts.values[pos]\n",
    "            if col not in numeric_col:\n",
    "                print(str(count) + '\\t' + questions[col][ind] )\n",
    "            else:\n",
    "                print(str(count) + '\\t' + str(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90adfe6-08aa-4e0c-bdf0-7db7df3534e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(data, idx, col, title, numeric_cols, questions):\n",
    "    plt.figure(idx)\n",
    "    if col not in numeric_cols:\n",
    "        val_cnts = data[col].value_counts()\n",
    "        text = [questions[col][val] for val in val_cnts.index]\n",
    "        # replace x and y with each other for vertical plot\n",
    "        ax = sns.barplot(y=text, x=val_cnts.values)\n",
    "        ax.set_title(title)\n",
    "        for ind, val in enumerate(val_cnts):\n",
    "            ax.text(val, ind, val, color='black', ha=\"center\")\n",
    "        #for plot vertical plot\n",
    "        #ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    else:\n",
    "        ax = sns.histplot(x=data[col])\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5223f-4a7e-4d18-b940-2b85f8b955c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_mapping(model_data, questions_map):\n",
    "    for index, row in model_data.iterrows():\n",
    "        for col in model_data.columns:\n",
    "            if np.isnan(row[col]) or row[col]==0:\n",
    "                continue\n",
    "            row[col] = questions_map[col][int(row[col])]\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec00e6a-def4-4237-ae1f-7327f1590cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logit(X_train, X_test, y_train, y_test, X_cols, y_col, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    X_train_df = pd.DataFrame(data=X_train_resampled, columns=X_cols)\n",
    "    y_train_df = pd.DataFrame(data=y_train_resampled, columns=y_col)\n",
    "    logit = Logit(y_train_df, X_train_df)\n",
    "    lg = logit.fit()\n",
    "    print(lg.summary())\n",
    "    yhat = lg.predict(X_test)\n",
    "    prediction = list(map(round, yhat))\n",
    "    get_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e2f9a-174d-40bc-8eb6-8c3efcb1c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest(X_train, X_test, y_train, y_test, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'criterion': criterion,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                                  n_iter = 100, scoring='accuracy', \n",
    "                                  cv = 7, verbose=2, random_state=42, n_jobs=-3,\n",
    "                                  return_train_score=True)\n",
    "    rf_random.fit(X_train_resampled, y_train_resampled)\n",
    "    pprint(rf_random.best_params_)\n",
    "    prediction = rf_random.best_estimator_.predict(X_test)\n",
    "    get_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d241ac-bf31-4737-a4d5-d3c289366039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_decision_tree(X_train, X_test, y_train, y_test, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    criterion = ['gini', 'entropy']\n",
    "    splitter = ['best', 'random']\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    random_grid = {'criterion': criterion,\n",
    "                   'splitter': splitter,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc_random = RandomizedSearchCV(estimator=dtc, param_distributions=random_grid,\n",
    "                                  n_iter = 100, scoring='accuracy', \n",
    "                                  cv = 7, verbose=2, random_state=42, n_jobs=-3,\n",
    "                                  return_train_score=True)\n",
    "    dtc_random.fit(X_train_resampled, y_train_resampled)\n",
    "    pprint(dtc_random.best_params_)\n",
    "    prediction = dtc_random.best_estimator_.predict(X_test)\n",
    "    get_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30680b-1a44-4177-bd6b-1918b1d7c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, prediction):\n",
    "    print(np.unique(y_true, return_counts=True))\n",
    "    print('Test ROC AUC: ', roc_auc_score(y_true, prediction))\n",
    "    print('Test accuracy: ', accuracy_score(y_true, prediction))\n",
    "    print('Test precision: ', precision_score(y_true, prediction))\n",
    "    print('Test recall: ', recall_score(y_true, prediction))\n",
    "    print('Test F1 score: ', f1_score(y_true, prediction))\n",
    "    print('Test confusion matrix: ')\n",
    "    print(confusion_matrix(y_true, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
