{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba6abad-3042-4bec-80b1-2b5cd1fa39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c18374-1d68-476a-9bf8-7961677e4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/'\n",
    "# IMG_DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/images/'\n",
    "# FIG_DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/figures/'\n",
    "DIR = ''\n",
    "IMG_DIR = 'images/'\n",
    "FIG_DIR = 'figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd13d1a-c5a3-487f-8327-598b5bfdeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_counts(data_subset):\n",
    "    for idx, col in enumerate(data_subset.columns):\n",
    "        print(questions[col]['text'])\n",
    "        print('Count:' + '\\t' + 'Answer:')\n",
    "        val_cnts = data_subset[col].value_counts()\n",
    "        for pos, ind in enumerate(val_cnts.index):\n",
    "            count = val_cnts.values[pos]\n",
    "            if col not in numeric_col:\n",
    "                print(str(count) + '\\t' + questions[col][ind] )\n",
    "            else:\n",
    "                print(str(count) + '\\t' + str(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90adfe6-08aa-4e0c-bdf0-7db7df3534e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(col, data, title, numeric_cols, questions):\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_str = 'barplot'\n",
    "    if col not in numeric_cols:\n",
    "        val_cnts = data[col].value_counts()\n",
    "        text = [questions[col][val] for val in val_cnts.index]\n",
    "        # replace x and y with each other for vertical plot\n",
    "        ax = sns.barplot(y=text, x=val_cnts.values)\n",
    "        ax.set_title(col+': '+title)\n",
    "        for ind, val in enumerate(val_cnts):\n",
    "            ax.text(val, ind, val, color='black', ha=\"center\")\n",
    "        #for plot vertical plot\n",
    "        #ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    else:\n",
    "        ax = sns.histplot(x=data[col])\n",
    "        ax.set_title(col+': '+title)\n",
    "        ax.set_xlabel('Age')\n",
    "        plot_str = 'histplot'\n",
    "    fig.savefig(FIG_DIR+col+'_'+plot_str+'.png', bbox_inches='tight', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec00e6a-def4-4237-ae1f-7327f1590cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logit(X_train, X_test, y_train, y_test, X_cols, y_col, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "    X_train_df = pd.DataFrame(data=X_train_resampled, columns=X_cols)\n",
    "    y_train_df = pd.DataFrame(data=y_train_resampled, columns=y_col)\n",
    "    logit = Logit(y_train_df, X_train_df)\n",
    "    lg = logit.fit()\n",
    "    print(lg.summary())\n",
    "    yhat = lg.predict(X_test)\n",
    "    prediction = list(map(round, yhat))\n",
    "    get_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e2f9a-174d-40bc-8eb6-8c3efcb1c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest(X_train, X_test, y_train, y_test, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "        \n",
    "    n_estimators = [int(x) for x in np.linspace(start = 5, stop = 150, num = 15)]\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_features = ['sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 100, num = 6)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'criterion': criterion,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    rf_scoring='accuracy'\n",
    "    rf_cv = 5\n",
    "    rf_verbose=1\n",
    "    rf_n_jobs=-1\n",
    "    rf_return_train_score=True\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_grid = GridSearchCV(estimator=rf, \n",
    "                            param_grid=random_grid,\n",
    "                            scoring=rf_scoring, cv=rf_cv, \n",
    "                            verbose=rf_verbose, n_jobs=rf_n_jobs, \n",
    "                            return_train_score=rf_return_train_score)\n",
    "    start_time = time.time()\n",
    "    rf_grid.fit(X_train_resampled, y_train_resampled)\n",
    "    end_time = time.time()\n",
    "    conv_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "    print(f\"Grid search time: {conv_time}\")\n",
    "    pprint(rf_grid.best_params_)\n",
    "    prediction = rf_grid.best_estimator_.predict(X_test)\n",
    "    get_metrics(y_test, prediction)\n",
    "    start_time = time.time()\n",
    "    importances = rf_grid.best_estimator_.feature_importances_\n",
    "    std = np.std([\n",
    "        rf_grid.best_estimator_.feature_importances_ for tree in rf_grid.best_estimator_.estimators_], axis=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed time to compute the importances: \" \n",
    "          f\"{elapsed_time:.3f} seconds\")\n",
    "    forest_importances = pd.Series(importances, index=X_cols)\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d241ac-bf31-4737-a4d5-d3c289366039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_decision_tree(X_train, X_test, y_train, y_test, balance=None):\n",
    "    if balance=='under':\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    elif balance=='over':\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    elif balance=='smoteenn':\n",
    "        smote_enn = SMOTEENN(random_state=0)\n",
    "        X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_resampled, y_train_resampled = X_train, y_train\n",
    "        \n",
    "    criterion = ['gini', 'entropy']\n",
    "    splitter = ['best', 'random']\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 50, num = 6)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    random_grid = {'criterion': criterion,\n",
    "                   'splitter': splitter,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "    dtc_scoring='accuracy'\n",
    "    dtc_cv = 5\n",
    "    dtc_verbose=1\n",
    "    dtc_n_jobs=-1\n",
    "    dtc_return_train_score=True\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc_grid = GridSearchCV(estimator=dtc, \n",
    "                            param_grid=random_grid,\n",
    "                            scoring=dtc_scoring, cv=dtc_cv, \n",
    "                            verbose=dtc_verbose, n_jobs=dtc_n_jobs, \n",
    "                            return_train_score=dtc_return_train_score)\n",
    "    start_time = time.time()\n",
    "    dtc_grid.fit(X_train_resampled, y_train_resampled)\n",
    "    end_time = time.time()\n",
    "    conv_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "    print(f\"Grid search time: {conv_time}\")\n",
    "    pprint(dtc_grid.best_params_)\n",
    "    prediction = dtc_grid.best_estimator_.predict(X_test)\n",
    "    get_metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30680b-1a44-4177-bd6b-1918b1d7c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, prediction):\n",
    "    print(np.unique(y_true, return_counts=True))\n",
    "    print('Test ROC AUC: ', roc_auc_score(y_true, prediction))\n",
    "    print('Test accuracy: ', accuracy_score(y_true, prediction))\n",
    "    print('Test precision: ', precision_score(y_true, prediction))\n",
    "    print('Test recall: ', recall_score(y_true, prediction))\n",
    "    print('Test F1 score: ', f1_score(y_true, prediction))\n",
    "    print('Test confusion matrix: ')\n",
    "    print(confusion_matrix(y_true, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
