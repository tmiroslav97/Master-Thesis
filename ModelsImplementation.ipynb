{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1bd141-9ff0-47ab-8340-887332f3fdc6",
   "metadata": {},
   "source": [
    "# Models implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc81e43e-9033-4ada-b7cd-82f1dda3f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b3d14-f7c6-4185-8b71-6fa5dfeaf65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG_DIR = '/content/drive/MyDrive/DentistDataAnalysis/Experiments/figures/'\n",
    "FIG_DIR = 'figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36781a1-6467-4a68-827f-08395266d791",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e79f90-bf82-4ced-8c0a-7082fbb477cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, prediction):\n",
    "    recall = round(recall_score(y_true, prediction), 4)\n",
    "    accuracy = round(accuracy_score(y_true, prediction), 4)\n",
    "    precision = round(precision_score(y_true, prediction), 4)\n",
    "    roc_auc = round(roc_auc_score(y_true, prediction), 4) \n",
    "    f1 = round(f1_score(y_true, prediction), 4)\n",
    "    conf_matrix = confusion_matrix(y_true, prediction).flatten()\n",
    "    \n",
    "    '''\n",
    "    print('Test recall:\\t', str(recall))\n",
    "    print('Test accuracy:\\t', str(accuracy))\n",
    "    print('Test precision:\\t', str(precision))\n",
    "    print('Test ROC AUC:\\t', str(roc_auc))\n",
    "    print('Test F1 score:\\t', str(f1))\n",
    "    print('Test confusion matrix:\\t'+ str(conf_matrix))\n",
    "    '''\n",
    "    return recall, accuracy, precision, roc_auc, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75b842-66b8-4793-8cb5-f2939f782365",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62df169c-13a4-4e3e-85bd-7f67fdca8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logit(X_train, y_train, X_test, y_test, X_cols, y_col, train_val_indices=None):\n",
    "    X_train_df = pd.DataFrame(data=X_train, columns=X_cols)\n",
    "    y_train_df = pd.DataFrame(data=y_train, columns=y_col)\n",
    "    best_model = None\n",
    "    best_score = None\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "    results = None\n",
    "    if train_val_indices is not None:\n",
    "        X_train_lg, X_test_lg = X_train_df.iloc[train_val_indices[0][0]], X_train_df.iloc[train_val_indices[0][1]]\n",
    "        y_train_lg, y_test_lg = y_train_df.iloc[train_val_indices[0][0]], y_train_df.iloc[train_val_indices[0][1]]\n",
    "        \n",
    "        X_train_lg = sm.add_constant(X_train_lg)\n",
    "        logit = Logit(y_train_lg, X_train_lg)\n",
    "        start_time = time.time()\n",
    "        results = logit.fit()\n",
    "        end_time = time.time()\n",
    "        X_test_lg = sm.add_constant(X_test_lg)\n",
    "        yhat = results.predict(X_test_lg)\n",
    "        prediction = list(map(round, yhat))\n",
    "        recall = round(recall_score(y_test_lg, prediction), 4)\n",
    "        best_score = recall\n",
    "        best_model = results\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        start_time = time.time()\n",
    "        for train_index, test_index in skf.split(X_train_df, y_train_df):\n",
    "            X_train_lg, X_test_lg = X_train_df.iloc[train_index], X_train_df.iloc[test_index]\n",
    "            y_train_lg, y_test_lg = y_train_df.iloc[train_index], y_train_df.iloc[test_index]\n",
    "\n",
    "            X_train_lg = sm.add_constant(X_train_lg)\n",
    "            logit = Logit(y_train_lg, X_train_lg)\n",
    "            results = logit.fit()\n",
    "            X_test_lg = sm.add_constant(X_test_lg)\n",
    "            yhat = results.predict(X_test_lg)\n",
    "            prediction = list(map(round, yhat))\n",
    "            recall = round(recall_score(y_test_lg, prediction), 4)\n",
    "\n",
    "            if best_score==None or best_score<recall:\n",
    "                best_score = recall\n",
    "                best_model = results\n",
    "        end_time = time.time()\n",
    "\n",
    "    conv_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "    \n",
    "    params = results.params\n",
    "    X_test = sm.add_constant(X_test)\n",
    "    yhat = best_model.predict(X_test)\n",
    "    prediction = list(map(round, yhat))\n",
    "    return best_score, get_metrics(y_test, prediction), conv_time, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5b2bd-3581-457e-b579-1abde5cd980e",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd0dea1-105f-4666-bba6-9ec9c8aac2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_decision_tree(X_train, y_train, X_test, y_test, train_val_indices=None):\n",
    "    #hyperparameters config\n",
    "    criterion = ['gini', 'entropy']\n",
    "    splitter = ['best', 'random']\n",
    "    max_features = ['sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 50, num = 6)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    search_grid = {'criterion': criterion,\n",
    "                   'splitter': splitter,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "    #grid search config\n",
    "    dtc_scoring='recall'\n",
    "    dtc_cv = 5\n",
    "    if train_val_indices is not None:\n",
    "        dtc_cv = train_val_indices\n",
    "    dtc_verbose=1\n",
    "    dtc_n_jobs=-1\n",
    "    dtc_return_train_score=True\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc_grid = GridSearchCV(estimator=dtc, \n",
    "                            param_grid=search_grid,\n",
    "                            scoring=dtc_scoring, cv=dtc_cv, \n",
    "                            verbose=dtc_verbose, n_jobs=dtc_n_jobs, \n",
    "                            return_train_score=dtc_return_train_score)\n",
    "    start_time = time.time()\n",
    "    dtc_grid.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    conv_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "    \n",
    "    val_score = round(dtc_grid.best_score_, 4)\n",
    "    params = dtc_grid.best_params_\n",
    "    \n",
    "    dtc_grid.best_estimator_.fit(X_train, y_train)\n",
    "    prediction = dtc_grid.best_estimator_.predict(X_test)\n",
    "    return val_score, get_metrics(y_test, prediction), conv_time, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62386836-631d-4a35-9d6c-b5dec1ac1d87",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31fa2ed-d69c-4b49-ab26-c2b77d664a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest(X_train, y_train, X_test, y_test, title, train_val_indices=None):\n",
    "    #hyperparameters config\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 5, stop = 150, num = 15)]\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_features = ['sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'criterion': criterion,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    #grid search config\n",
    "    rf_scoring='recall'\n",
    "    rf_cv = 5\n",
    "    if train_val_indices is not None:\n",
    "        rf_cv = train_val_indices\n",
    "    rf_verbose=1\n",
    "    rf_n_jobs=-1\n",
    "    rf_return_train_score=True\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_grid = GridSearchCV(estimator=rf, \n",
    "                            param_grid=random_grid,\n",
    "                            scoring=rf_scoring, cv=rf_cv, \n",
    "                            verbose=rf_verbose, n_jobs=rf_n_jobs, \n",
    "                            return_train_score=rf_return_train_score)\n",
    "    start_time = time.time()\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    conv_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "    \n",
    "    val_score = round(rf_grid.best_score_, 4)\n",
    "    params = rf_grid.best_params_\n",
    " \n",
    "    rf_grid.best_estimator_.fit(X_train, y_train)\n",
    "    prediction = rf_grid.best_estimator_.predict(X_test)\n",
    "    metrics = get_metrics(y_test, prediction)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    importances = rf_grid.best_estimator_.feature_importances_\n",
    "    std = np.std([rf_grid.best_estimator_.feature_importances_ for tree in rf_grid.best_estimator_.estimators_], axis=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed time to compute the importances: \" \n",
    "          f\"{elapsed_time:.3f} seconds\")\n",
    "    forest_importances = pd.Series(importances, index=X_cols).sort_values(ascending=False)\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(FIG_DIR+title.replace(' ', '_')+'.png', bbox_inches='tight', dpi=fig.dpi)\n",
    "    return val_score, metrics, conv_time, params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
